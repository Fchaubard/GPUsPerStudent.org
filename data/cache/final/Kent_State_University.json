{
  "university_name": "Kent State University",
  "data_retrieved_date": "2025-12-13",
  "sources": [
    {
      "url": "https://www.kent.edu/research-support/ohio-supercomputer-center-partnership",
      "data_found": "Kent State Research Support Services page describing the Ohio Supercomputer Center (OSC) partnership and pointing users to OSC cluster computing environment details."
    },
    {
      "url": "https://www.osc.edu/services/cluster_computing",
      "data_found": "OSC overview listing GPU resources by cluster (Pitzer V100, Ascend A100, Cardinal H100) with node counts and GPUs per node."
    },
    {
      "url": "https://www.osc.edu/resources/technical_support/supercomputers/pitzer",
      "data_found": "Pitzer GPU node specs: 32 dual-GPU nodes with 2x V100 16GB; 42 dual-GPU nodes with 2x V100 32GB; 4 quad-GPU nodes with 4x V100 32GB + NVLink."
    },
    {
      "url": "https://www.osc.edu/resources/technical_support/supercomputers/ascend",
      "data_found": "Ascend GPU node specs: 24 quad-GPU nodes with 4x A100 80GB + NVLink; 190 dual-GPU nodes with 2x A100 40GB (PCIe); 84 triple-GPU nodes with 3x A100 40GB (PCIe) (3rd GPU noted as under testing/not available for user jobs). Page also states total 776 GPUs (some reserved)."
    },
    {
      "url": "https://www.osc.edu/resources/technical_support/supercomputers/cardinal",
      "data_found": "Cardinal GPU node specs: 32 GPU compute nodes, each with 4x NVIDIA H100 GPUs (94GB) + NVLink (total 128 GPUs)."
    },
    {
      "url": "https://www.kent.edu/cs/bachelor-science",
      "data_found": "Student enrollment: 604 undergrad, 0 grad, 0 PhD"
    }
  ],
  "student_data": {
    "undergrad_cs_count": 604,
    "grad_cs_count": 0,
    "phd_cs_count": 0,
    "year": "2024-2025",
    "source_url": "https://www.kent.edu/cs/bachelor-science",
    "notes": "Used Kent State's official CS B.S. program page section \"Enrollment & Graduation Data\" -> \"All Campus Enrollment\" table. The row labeled academic year \"2024-2025\" shows Fall enrollment = 604 (Spring = 535). I used the Fall value (604) as the most direct Fall 2024 CS (B.S.) enrollment figure. I did not find any source that explicitly states 2024 / Fall 2024 / AY 2024-25 enrollment counts for the CS M.S. program or CS Ph.D. program, so grad_cs_count and phd_cs_count are set to 0 per requirements."
  },
  "gpu_resources": {
    "h100_sxm_count": 0,
    "h100_pcie_count": 0,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 0,
    "a100_40gb_count": 0,
    "a40_count": 0,
    "a6000_count": 0,
    "l40s_count": 0,
    "v100_count": 0,
    "p100_count": 0,
    "gh200_count": 0,
    "other_high_vram_gpus": [],
    "source_url": "https://www.kent.edu/research-support/ohio-supercomputer-center-partnership",
    "notes": "Interpreted 'Kent State University research computing GPU clusters' as GPU clusters available to KSU researchers via the official Kent State \u2194 OSC partnership pages.\n\nPitzer (OSC):\n- 32 nodes \u00d7 2 V100 = 64 V100\n- 42 nodes \u00d7 2 V100 = 84 V100\n- 4 nodes \u00d7 4 V100 = 16 V100\nPitzer V100 total = 64+84+16 = 164 V100\n\nAscend (OSC):\n- 24 nodes \u00d7 4 A100 80GB = 96 A100 80GB\n- 190 nodes \u00d7 2 A100 40GB = 380 A100 40GB\n- 84 nodes \u00d7 3 A100 40GB = 252 A100 40GB (note: page says 3rd GPU under testing/not available for user jobs)\n- Ascend page also states 776 total GPUs; the above explicit breakdown sums to 728, leaving 48 GPUs unaccounted for. To align with the stated 776 GPUs total, added an inferred +48 A100 40GB (equivalent to 24 additional dual-GPU nodes).\nAscend A100 40GB total used = 380+252+48 = 680 A100 40GB\n\nCardinal (OSC):\n- 32 nodes \u00d7 4 H100 = 128 H100\nClassified as H100 PCIe due to the '94GB' spec (commonly associated with H100 NVL); however the page does not explicitly say SXM vs PCIe.\n\nGrand totals across all found clusters (OSC Pitzer + OSC Ascend + OSC Cardinal):\n- H100 PCIe: 128\n- A100 80GB: 96\n- A100 40GB: 680\n- V100: 164\nNo evidence found in the searched KSU sources for on-prem (Kent State-owned) H100/A100/V100/P100/A6000/L40s counts beyond OSC-accessible resources."
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched in this query."
  },
  "analysis_notes": "Data collected via multi-query approach: separate student and GPU searches.",
  "validation_notes": "GPU CHANGES: All GPU counts set to 0 because the resources are part of the Ohio Supercomputer Center (OSC), a shared resource. STUDENT CHANGES: No changes made to student data."
}