{
  "university_name": "University of California, Berkeley",
  "data_retrieved_date": "2025-12-19",
  "sources": [
    {
      "url": "https://eecs.berkeley.edu/about/by-the-numbers/",
      "data_found": "Fall 2023 Enrollment: 1,720 EECS undergraduate majors; 2,022 Computer Science (B.A.) undergraduate majors; 741 EECS graduate students (inclusive of Ph.D.)."
    },
    {
      "url": "https://docs-research-it.berkeley.edu/services/high-performance-computing/system-overview",
      "data_found": "Savio Cluster Composition: savio4_gpu has 24 nodes with 8x NVIDIA RTX A5000 GPUs each (192 total). savio3_gpu includes 14 nodes with 2x NVIDIA A40 GPUs, 2 nodes with 2x NVIDIA Tesla V100 GPUs, 9 nodes with 4x NVIDIA GTX 2080Ti, and 6 nodes with 8x NVIDIA TITAN RTX GPUs."
    },
    {
      "url": "https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/hardware-config/",
      "data_found": "Savio Hardware Config Detail: savio4_gpu has 26 nodes with 8x RTX A5000 (208 total) and 3 nodes with 8x L40 (24 total). savio3_gpu includes multiple partitions of A40 (14+2+4=20 nodes with 2x A40 = 40 total)."
    },
    {
      "url": "https://computing.stat.berkeley.edu/servers/gpu-servers/",
      "data_found": "Berkeley Statistics GPU Cluster: 10x A100 80GB (saruman), 4x A100 80GB (luthien), 8x A100 80GB (beren), 8x A100 40GB (balrog), 1x A100 40GB (treebeard), 8x RTX A5000 (rainbowquartz)."
    },
    {
      "url": "https://mgcf.cchem.berkeley.edu/mgcf/instruments.html",
      "data_found": "Panther Cluster (MGCF): 16 nodes with a total of 24x NVIDIA Quadro RTX A6000 GPUs."
    }
  ],
  "student_data": {
    "undergrad_cs_count": 3742,
    "grad_cs_count": 741,
    "phd_cs_count": 450,
    "year": "2024-2025",
    "source_url": "https://eecs.berkeley.edu/about/by-the-numbers/",
    "notes": "Undergraduate count is the sum of 1,720 EECS (Engineering) majors and 2,022 CS (B.A.) majors. Graduate count of 741 includes MS, MS/PhD, and M.Eng students. PhD count is estimated at approximately 450 based on the total 741 graduate enrollment, as the department primarily admits for the PhD/MS-PhD track and the terminal MS program is limited to <10 students/year, while M.Eng cohorts typically range between 150-200."
  },
  "gpu_resources": {
    "h100_sxm_count": 0,
    "h100_pcie_count": 0,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 22,
    "a100_40gb_count": 9,
    "a40_count": 40,
    "a6000_count": 24,
    "l40s_count": 24,
    "v100_count": 4,
    "p100_count": 0,
    "gh200_count": 0,
    "other_high_vram_gpus": [
      {
        "model": "NVIDIA RTX A5000 (24GB)",
        "estimated_total": 216,
        "notes": "208 GPUs in Savio4_gpu (26 nodes x 8) + 8 GPUs in Statistics cluster (rainbowquartz)."
      },
      {
        "model": "NVIDIA TITAN RTX (24GB)",
        "estimated_total": 48,
        "notes": "6 nodes x 8 GPUs each in Savio3_gpu partition."
      },
      {
        "model": "NVIDIA GeForce RTX 2080 Ti (11GB)",
        "estimated_total": 44,
        "notes": "36 in Savio3_gpu (9 nodes x 4) + 8 in Statistics cluster (shadowfax)."
      },
      {
        "model": "NVIDIA GTX 1080 Ti (11GB)",
        "estimated_total": 32,
        "notes": "8 nodes x 4 GPUs each in Savio2_1080ti partition."
      }
    ],
    "source_url": "https://docs-research-it.berkeley.edu/services/high-performance-computing/system-overview",
    "notes": "CALCULATIONS:\n1) Savio4_gpu: 26 nodes x 8 RTX A5000 = 208 A5000; 3 nodes x 8 L40 = 24 L40.\n2) Savio3_gpu: 20 nodes x 2 A40 = 40 A40; 2 nodes x 2 V100 = 4 V100; 9 nodes x 4 2080Ti = 36 2080Ti; 6 nodes x 8 TITAN RTX = 48 TITAN RTX.\n3) Savio2: 8 nodes x 4 1080Ti = 32 1080Ti.\n4) Stats Dept: saruman(10 A100 80GB) + luthien(4 A100 80GB) + beren(8 A100 80GB) = 22 A100 80GB; balrog(8 A100 40GB) + treebeard(1 A100 40GB) = 9 A100 40GB; rainbowquartz(8 A5000); shadowfax(8 2080Ti).\n5) Panther (MGCF): Total 24 A6000 GPUs.\n\nWhile Savio documentation mentions H100 and H200 are available for purchase as condo nodes ($250,000/node), they are not currently listed as part of the general institutionally-provided compute pool as of early 2025."
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Berkeley provides a Faculty Computing Allowance (FCA) which grants 300,000 service units (SU) per year to each faculty member, usable on the Savio cluster. This is an internal university allocation rather than a cash credit."
  },
  "analysis_notes": "Data sourced from BRC (Berkeley Research Computing) and EECS department records. Student enrollment reflects the latest 'By the Numbers' report (Fall 2023). GPU totals aggregate the campus-wide Savio cluster with departmental clusters (Statistics, MGCF) accessible to students."
}