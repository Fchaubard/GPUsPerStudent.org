{
  "university_name": "University of Florida",
  "data_retrieved_date": "2025-12-15",
  "sources": [
    {
      "url": "https://gravity.rc.ufl.edu/revolutionizing-patient-care-with-ai/",
      "data_found": "HiPerGator AI described as an NVIDIA DGX SuperPOD of 140 DGX A100 nodes and states it has 1,120 Ampere A100 GPUs."
    },
    {
      "url": "https://www.rc.ufl.edu/about/hipergator/",
      "data_found": "States the original HiPerGator AI DGX SuperPOD of 140 DGX A100 nodes was replaced in 2025 by 63 DGX B200 nodes (8 GPUs each), and mentions 600 NVIDIA L4 GPUs for HiPerGator 4.0."
    },
    {
      "url": "https://news.ufl.edu/2025/10/hipergator-4-unveiling/",
      "data_found": "States 63 NVIDIA DGX B200 nodes, each with 8 GPUs, for a total of 504 GPUs."
    },
    {
      "url": "https://docs.rc.ufl.edu/scheduler/gpu_access/",
      "data_found": "Lists current GPU node types and quantities for scheduling: L4 hosts (200 hosts, 3 GPUs/host) and B200 hosts (31 hosts, 8 GPUs/host) for the first scalable unit (SU1)."
    },
    {
      "url": "https://blogs.nvidia.com.tw/blog/nvidia-dgx-station-a100-offers-researchers-ai-data-center-in-a-box/",
      "data_found": "Mentions DGX A100 systems being available with A100 80GB GPUs (i.e., DGX A100 640GB); used as supporting context for assuming UF\u2019s DGX A100 SuperPOD used 80GB A100s (not explicitly stated on UF pages)."
    },
    {
      "url": "https://data-apps.ir.aa.ufl.edu/public/cds/CDS_2024-2025_UFMAIN_Post_v3.pdf",
      "data_found": "Student enrollment: 0 undergrad, 0 grad, 0 PhD"
    }
  ],
  "student_data": {
    "undergrad_cs_count": 0,
    "grad_cs_count": 0,
    "phd_cs_count": 0,
    "year": "NO_RECENT_DATA_FOUND",
    "source_url": "https://data-apps.ir.aa.ufl.edu/public/cds/CDS_2024-2025_UFMAIN_Post_v3.pdf",
    "notes": "Searched for UF Computer Science (CS/CISE) student enrollment counts specifically for AY 2024-2025 or Fall 2024. Verified UF has a Common Data Set explicitly labeled 2024-2025 (source_url), but it only contains institution-wide enrollment totals (and other general CDS items) and does NOT provide Computer Science major/program headcount enrollment or a breakdown into BS vs MS vs PhD for CS. Also searched UF IPR 'Enrollment' pages/dashboards, UF Registrar enrollment statistics, and CISE department pages for Fall 2024/AY 2024-25 CS enrollment counts (undergrad, MS-only, PhD-only) and did not find any publicly posted 2024+ CS-specific enrollment headcount figures. Per requirement, all counts are set to 0 because no acceptable 2024+ CS enrollment numbers were located on a page explicitly labeled 2024 / Fall 2024 / AY 2024-25."
  },
  "gpu_resources": {
    "h100_sxm_count": 0,
    "h100_pcie_count": 0,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 1120,
    "a100_40gb_count": 0,
    "a40_count": 0,
    "a6000_count": 0,
    "l40s_count": 0,
    "v100_count": 0,
    "p100_count": 0,
    "gh200_count": 0,
    "other_high_vram_gpus": [
      {
        "model": "NVIDIA B200 (180GB)",
        "count": 504,
        "clusters": [
          "HiPerGator AI (DGX B200 SuperPOD, 2025)"
        ],
        "calculation": "63 DGX B200 nodes \u00d7 8 GPUs/node = 504"
      }
    ],
    "source_url": "https://www.rc.ufl.edu/about/hipergator/",
    "notes": "Clusters found and calculations:\n1) HiPerGator AI (DGX A100 SuperPOD, circa 2021): 140 DGX A100 nodes \u00d7 8 GPUs/node = 1,120 total A100 GPUs (from UF RC news article). A100 VRAM (80GB vs 40GB) is not explicitly stated on UF pages; counted as A100_80gb_count by estimate because DGX A100 '640GB' corresponds to 8\u00d780GB.\n2) HiPerGator AI upgrade (DGX B200 SuperPOD, 2025): 63 DGX B200 nodes \u00d7 8 GPUs/node = 504 total B200 GPUs (not counted in b200_count per requested schema; included under other_high_vram_gpus). UF docs also show SU1 early-access slice: 31 hosts \u00d7 8 = 248 B200 GPUs.\n3) HiPerGator 4.0 GPUs: 200 L4 hosts \u00d7 3 GPUs/host = 600 NVIDIA L4 GPUs (not included in requested fields; L4 is 24GB and not 'L40S').\nNo UF sources found indicating any H100/H200, V100, P100, RTX A6000, L40S, A40, GH200 in UF Research Computing clusters."
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched in this query."
  },
  "analysis_notes": "Data collected via multi-query approach: separate student and GPU searches."
}