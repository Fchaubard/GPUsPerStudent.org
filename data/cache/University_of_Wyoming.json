{
  "university_name": "University of Wyoming",
  "data_retrieved_date": "2025-12-15",
  "sources": [
    {
      "url": "https://arccwiki.atlassian.net/wiki/spaces/DOCUMENTAT/pages/2117402626",
      "data_found": "MedicineBow GPU table: mb-h100 (6 nodes, 8 GPUs/node, 80GB/GPU; key attributes elsewhere on page indicate Nvidia SXM5 H100), mb-l40s (5 nodes, 8 GPUs/node, 48GB/GPU)."
    },
    {
      "url": "https://arccwiki.atlassian.net/wiki/spaces/DOCUMENTAT/pages/2103312408",
      "data_found": "Facilities Statement: mb-a6000 (1 node, 4x A6000 GPUs)."
    },
    {
      "url": "https://arccwiki.atlassian.net/wiki/spaces/DOCUMENTAT/pages/33184",
      "data_found": "FAQ showpartitions example (Tue Feb 11 2025): teton-gpu partition shown with 10 nodes; used to estimate P100 totals assuming historical teton-gpu configuration."
    },
    {
      "url": "https://arccwiki.atlassian.net/wiki/spaces/DOCUMENTAT/pages/1586364445/Teton%2BHardware%2BSummary%2BTable",
      "data_found": "Teton Hardware Summary (Updated May 03, 2024; archived): teton-gpu uses Tesla P100 with 2 GPUs/node; dgx nodes exist (historically V100-based DGX)."
    },
    {
      "url": "https://arccwiki.atlassian.net/wiki/spaces/DOCUMENTAT/pages/1721139201/Beartooth%2BHardware%2BSummary%2BTable",
      "data_found": "Beartooth Hardware Summary (July 26, 2023 data; archived): V100 on dgx partition = 2 nodes with 8 GPUs/node."
    },
    {
      "url": "https://news.ucar.edu/132774/new-ncar-wyoming-supercomputer-accelerate-scientific-discovery",
      "data_found": "NWSC (NCAR-Wyoming Supercomputing Center) system: 82 GPU nodes, each with 4x NVIDIA A100 GPUs (40GiB). Also notes two login nodes each with 2x NVIDIA V100 GPUs."
    },
    {
      "url": "https://www.uwyo.edu/news/2024/08/uw-wins-4m-to-install-state-of-the-art-research-computing-system.html",
      "data_found": "AI4WY acquisition described as a testbed of 24 nodes of NVIDIA Grace Hopper Superchips (counted as 24 GH200-class GPUs at 1 GPU per node)."
    },
    {
      "url": "https://www.uwyo.edu/oia/_files/enrollment/dup-majors-2024.pdf",
      "data_found": "Student enrollment: 196 undergrad, 11 grad, 23 PhD"
    }
  ],
  "student_data": {
    "undergrad_cs_count": 196,
    "grad_cs_count": 11,
    "phd_cs_count": 23,
    "year": "Fall 2024 (Day 15)",
    "source_url": "https://www.uwyo.edu/oia/_files/enrollment/dup-majors-2024.pdf",
    "notes": "Source is the University of Wyoming Office of Institutional Analysis (OIA) PDF report titled 'Day 15 Duplicated* Headcounts by Department' with columns Fall 2020, Fall 2021, Fall 2022, Fall 2023, Fall 2024. In the Electrical Engineering & Computer Science department section, the Fall 2024 column lists: 'BS in Computer Science' = 196 (used for undergrad_cs_count), 'MS in Computer Science' = 11 (used for grad_cs_count; masters only), and 'PhD in Computer Science' = 23 (used for phd_cs_count). Note: this report is explicitly labeled 'Duplicated*' (students with multiple majors can appear in multiple rows). A separate row 'Secondary Bachelors in Computer Science*' lists 35 for Fall 2024; that secondary-major count is not included in undergrad_cs_count above. ([uwyo.edu](https://www.uwyo.edu/oia/_files/enrollment/dup-majors-2024.pdf))"
  },
  "gpu_resources": {
    "h100_sxm_count": 48,
    "h100_pcie_count": 0,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 0,
    "a100_40gb_count": 328,
    "a40_count": 0,
    "a6000_count": 4,
    "l40s_count": 40,
    "v100_count": 20,
    "p100_count": 20,
    "gh200_count": 24,
    "other_high_vram_gpus": [],
    "source_url": "https://arccwiki.atlassian.net/wiki/spaces/DOCUMENTAT/pages/2117402626",
    "notes": "Clusters tallied:\n\n1) UW ARCC MedicineBow (on-prem):\n- H100 SXM5: mb-h100 = 6 nodes \u00d7 8 GPUs/node = 48 H100 (counted as H100 SXM).\n- L40S: mb-l40s = 5 nodes \u00d7 8 GPUs/node = 40 L40S.\n- A6000: mb-a6000 = 1 node \u00d7 4 GPUs/node = 4 A6000.\n\n2) UW ARCC legacy partitions still referenced in MedicineBow-era outputs:\n- P100 (estimated): teton-gpu shown as 10 nodes in a Feb 11, 2025 showpartitions example; Teton hardware table indicates teton-gpu uses Tesla P100 at 2 GPUs/node => 10 \u00d7 2 = 20 P100. (Type inference: assumes teton-gpu remains P100 as historically documented.)\n- V100: dgx partition documented as 2 nodes \u00d7 8 GPUs/node = 16 V100.\n\n3) NCAR-Wyoming Supercomputing Center (external UW-access resource):\n- A100 40GB: 82 GPU nodes \u00d7 4 A100/node = 328 A100 40GB.\n- V100 (login nodes): 2 login nodes \u00d7 2 V100/node = 4 V100.\n\n4) AI4WY (planned/acquisition described by UW, Aug 28 2024):\n- Grace Hopper Superchip nodes: 24 nodes \u00d7 1 GPU/node assumed = 24 GH200.\n\nGrand totals from the above:\n- H100 SXM = 48; L40S = 40; A6000 = 4; P100 = 20 (estimated as noted); V100 = 16 + 4 = 20; A100 40GB = 328; GH200 = 24.\nNo sources found indicating any H200, A100 80GB, A100 40GB on-prem at UW ARCC, B100/B200, or H100 PCIe specifically."
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched in this query."
  },
  "analysis_notes": "Data collected via multi-query approach: separate student and GPU searches."
}