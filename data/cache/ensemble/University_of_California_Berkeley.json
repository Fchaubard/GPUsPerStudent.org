{
  "university_name": "University of California, Berkeley",
  "data_retrieved_date": "2025-12-13",
  "sources": [
    {
      "url": "https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/hardware-config/",
      "data_found": "Savio GPU hardware table lists: savio4_gpu 26 nodes w/8x RTX A5000; savio4_gpu 3 nodes w/8x L40; savio3_gpu two V100 nodes (each 2x V100); multiple A40 node groups (14,2,4 nodes each w/2x A40). Also notes retired savio2_gpu K80 nodes."
    },
    {
      "url": "https://computing.stat.berkeley.edu/servers/gpu-servers/",
      "data_found": "Statistics SCF GPU servers table lists per-machine GPU counts: A100 40GB (balrog 8; treebeard 1), A100 80GB (saruman 10; luthien 4; beren 8; remote cluster A100(40) 80GB with footnote stating 5 machines), H200 144GB (feanor 8; lorax 8), plus Quadro RTX 8000 (smaug 1)."
    },
    {
      "url": "https://docs-research-it.berkeley.edu/services/high-performance-computing/condos/condo-cluster-service/",
      "data_found": "Mentions supported (purchasable) standard condo offerings for savio4_gpu include an 8-way L40S server and an 8-way H100 Dell server, but does not provide installed node counts; therefore H100/L40S totals not incremented from this source."
    },
    {
      "url": "https://opa.berkeley.edu/campus-data/uc-berkeley-quick-facts",
      "data_found": "Student enrollment: 0 undergrad, 0 grad, 0 PhD"
    }
  ],
  "student_data": {
    "undergrad_cs_count": 0,
    "grad_cs_count": 0,
    "phd_cs_count": 0,
    "year": "NO_RECENT_DATA_FOUND",
    "source_url": "https://opa.berkeley.edu/campus-data/uc-berkeley-quick-facts",
    "notes": "Searched for UC Berkeley Computer Science (CS) student enrollment counts specifically for Fall 2024 or AY 2024-2025. The official UC Berkeley OPA \u201cQuick Facts\u201d page explicitly reports Fall 2024 total campus enrollment (33,070 undergraduates; 12,812 graduate students) but does NOT provide CS-specific enrollment breakdowns (e.g., CS undergrad majors, MS-only, PhD-only). Attempted to use OPA\u2019s Student Enrollment dashboard (CalViz/Tableau) linked from OPA pages (e.g., https://opa.berkeley.edu/student-enrollment), but the public dashboard content was not accessible in a way that exposes the underlying CS-major enrollment counts. Departmental \u2018By the Numbers\u2019 sources were found but explicitly labeled Fall 2023 (rejected per requirement). Therefore, no acceptable 2024+ CS-specific enrollment counts (undergrad CS, MS-only CS, PhD-only CS) could be verified from a source that explicitly states Fall 2024 / AY 2024-2025 on the CS enrollment numbers themselves, so all counts are returned as 0."
  },
  "gpu_resources": {
    "h100_sxm_count": 0,
    "h100_pcie_count": 0,
    "h200_count": 16,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 62,
    "a100_40gb_count": 9,
    "a40_count": 0,
    "a6000_count": 0,
    "l40s_count": 0,
    "v100_count": 4,
    "p100_count": 0,
    "gh200_count": 0,
    "other_high_vram_gpus": [
      {
        "model": "NVIDIA L40 (48GB-class; listed as 46GB on Savio docs)",
        "count": 24,
        "notes": "Savio savio4_gpu: 3 nodes \u00d7 8 L40 per node = 24 (note: L40, not L40S)."
      },
      {
        "model": "NVIDIA A40 48GB",
        "count": 41,
        "notes": "Savio savio3_gpu: (14+2+4)=20 nodes \u00d7 2 A40 per node = 40; plus EML cluster: 1 node \u00d7 1 A40 = 1; total A40=41."
      },
      {
        "model": "NVIDIA Quadro RTX 8000 48GB",
        "count": 1,
        "notes": "SCF GPU servers: smaug: 1 machine \u00d7 1 RTX 8000 = 1."
      }
    ],
    "source_url": "https://docs-research-it.berkeley.edu/services/high-performance-computing/user-guide/hardware-config/",
    "notes": "Clusters included: (1) UC Berkeley Savio (BRC) GPU partitions; (2) UC Berkeley Statistics SCF GPU Servers/remote cluster; (3) UC Berkeley Econometrics Lab (EML) cluster GPU partition.\n\nSavio (from hardware-config):\n- V100: 2 nodes \u00d7 2 V100/node = 4 V100.\n- L40: 3 nodes \u00d7 8 L40/node = 24 L40 (NOT L40S; so l40s_count remains 0).\n- A40: (14+2+4)=20 nodes \u00d7 2 A40/node = 40 A40 (recorded under other_high_vram_gpus; a40_count forced to 0 per output schema).\n- No A100/H100/H200 listed in Savio hardware table.\n- Retired (not counted): savio2_gpu K80: 17 nodes \u00d7 4 = 68 K80 (explicitly marked retired / no longer accessible).\n\nStatistics SCF GPU Servers (from SCF GPU Servers table):\n- H200: feanor 1\u00d78=8; lorax 1\u00d78=8; total H200=16.\n- A100 80GB: saruman 1\u00d710=10; luthien 1\u00d74=4; beren 1\u00d78=8; remote cluster A100(40) with footnote 'five machines' => 5\u00d78=40; total A100 80GB = 10+4+8+40 = 62.\n- A100 40GB: balrog 1\u00d78=8; treebeard 1\u00d71=1; total A100 40GB = 9.\n- Quadro RTX 8000: smaug 1\u00d71=1 (recorded under other_high_vram_gpus).\n\nEconometrics Lab (EML):\n- A40: 1 node \u00d7 1 A40 = 1 (recorded under other_high_vram_gpus).\n\nFinal requested totals:\n- h100_sxm_count=0; h100_pcie_count=0 (no install counts found).\n- h200_count=16.\n- a100_80gb_count=62.\n- a100_40gb_count=9.\n- v100_count=4.\n- p100_count=0; a6000_count=0; l40s_count=0."
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched in this query."
  },
  "analysis_notes": "Data collected via multi-query approach: separate student and GPU searches."
}