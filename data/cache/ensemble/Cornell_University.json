{
  "university_name": "Cornell University",
  "data_retrieved_date": "2025-12-13",
  "sources": [
    {
      "url": "https://empireai.freshdesk.com/support/solutions/articles/157000363466-alpha-beta-hardware-fall-2025-",
      "data_found": "Empire AI Alpha+ upgrade: 18 HGX nodes, 8\u00d7 H100 80GB GPUs per node (Alpha+ total H100=144); Beta: 288 B200 GPUs (not counted into b200_count per requested schema). ([empireai.freshdesk.com](https://empireai.freshdesk.com/support/solutions/articles/157000363466-alpha-beta-hardware-fall-2025-))"
    },
    {
      "url": "https://portal.cac.cornell.edu/techdocs/clusters/seneca/",
      "data_found": "Seneca compute nodes c0001-c0004 each have 4\u00d7 Nvidia H100 80GB HBM3 (4 nodes total). ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/seneca/))"
    },
    {
      "url": "https://portal.cac.cornell.edu/TechDocs/clusters/keuka/",
      "data_found": "Keuka hardware: node c0001 has 2\u00d7 H100; node c0002 has 2\u00d7 A100. ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/TechDocs/clusters/keuka/?utm_source=openai))"
    },
    {
      "url": "https://portal.cac.cornell.edu/techdocs/clusters/altas/",
      "data_found": "ALTAS hardware: 4 compute nodes (c0001-c0004), each with 4\u00d7 Nvidia A100 GPUs. MIG examples include 2g.20gb / 1g.10gb (used to infer A100 80GB). ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/altas/?utm_source=openai))"
    },
    {
      "url": "https://portal.cac.cornell.edu/techdocs/clusters/yuegroup/",
      "data_found": "Yuegroup: 4 compute nodes (c0001-c0004), each with 4\u00d7 Nvidia A100 GPUs; scheduler notes an A6000 GPU node c0005 but does not state GPU count. MIG example includes 3g.20gb (used to infer A100 80GB). ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/yuegroup/))"
    },
    {
      "url": "https://portal.cac.cornell.edu/techdocs/clusters/capecrystal/",
      "data_found": "CAPECRYSTAL: 5 GPU compute nodes c000[1-5]; each node contains 4\u00d7 Tesla V100 SXM2 32GB GPUs. ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/capecrystal/?utm_source=openai))"
    },
    {
      "url": "https://portal.cac.cornell.edu/techdocs/clusters/pool-hardware/",
      "data_found": "POOL hardware table lists node c0105 with \"8\u00d7 RTX A6000 ADA Lovelace 48Gb\". ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/pool-hardware/))"
    },
    {
      "url": "https://irp.dpb.cornell.edu/wp-content/uploads/2025/07/CDS-2024-2025-v6-print.pdf",
      "data_found": "Student enrollment: 0 undergrad, 0 grad, 0 PhD"
    }
  ],
  "student_data": {
    "undergrad_cs_count": 0,
    "grad_cs_count": 0,
    "phd_cs_count": 0,
    "year": "NO_RECENT_DATA_FOUND",
    "source_url": "https://irp.dpb.cornell.edu/wp-content/uploads/2025/07/CDS-2024-2025-v6-print.pdf",
    "notes": "Searched for Cornell CS student enrollment counts explicitly labeled Fall 2024 / AY 2024-2025 (including Cornell IRP/Factbook, registrar pages, and CS/Bowers CIS pages). The only clearly dated 2024+ official enrollment source found was Cornell IRP's Common Data Set 2024-2025 PDF, which reports overall institutional enrollment (as of the official fall reporting date / Oct 15, 2024) but does NOT provide Computer Science major enrollment breakdowns (undergrad vs MS vs PhD) by program/major/field. Because no official Cornell source with explicit Fall 2024 or AY 2024-2025 CS-major headcounts was located in accessible pages, all requested CS counts are set to 0 per instructions. ([irp.dpb.cornell.edu](https://irp.dpb.cornell.edu/wp-content/uploads/2025/07/CDS-2024-2025-v6-print.pdf))"
  },
  "gpu_resources": {
    "h100_sxm_count": 144,
    "h100_pcie_count": 22,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 38,
    "a100_40gb_count": 0,
    "a40_count": 8,
    "a6000_count": 12,
    "l40s_count": 0,
    "v100_count": 20,
    "p100_count": 0,
    "gh200_count": 0,
    "other_high_vram_gpus": [
      {
        "model": "RTX A6000 Ada Lovelace 48GB",
        "count": 8,
        "source_url": "https://portal.cac.cornell.edu/techdocs/clusters/pool-hardware/"
      }
    ],
    "source_url": "https://empireai.freshdesk.com/support/solutions/articles/157000363466-alpha-beta-hardware-fall-2025-",
    "notes": "Totals computed by summing per-cluster (nodes \u00d7 GPUs_per_node):\n\n1) Empire AI Alpha+ (consortium resource Cornell can allocate to): 18 nodes \u00d7 8 H100/node = 144 H100 (counted as H100 SXM because \"HGX nodes\" implies SXM modules). ([empireai.freshdesk.com](https://empireai.freshdesk.com/support/solutions/articles/157000363466-alpha-beta-hardware-fall-2025-))\n\n2) Seneca: 4 nodes \u00d7 4 H100/node = 16 H100 (counted as H100 PCIe due to no explicit SXM/HGX wording). ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/seneca/))\n\n3) Cayuga: A100: 1 node \u00d7 4 A100 80GB PCIe/node = 4 A100_80GB; A40: 2 nodes \u00d7 4 A40/node = 8 A40; H100: 1 node \u00d7 4 H100/node = 4 H100 (counted as H100 PCIe because form factor not stated). ([github.com](https://github.com/CornellCAC/Cayuga/wiki))\n\n4) Keuka: H100: 1 node \u00d7 2 H100/node = 2 H100 (counted as H100 PCIe because only 2 GPUs/node and no HGX/SXM stated); A100: 1 node \u00d7 2 A100/node = 2 A100 (A100 memory size not stated; estimated as A100 80GB due to similar CAC A100 clusters using MIG 10GB/20GB slices typical of 80GB parts). ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/TechDocs/clusters/keuka/?utm_source=openai))\n\n5) ALTAS: 4 nodes \u00d7 4 A100/node = 16 A100; inferred A100 80GB from MIG examples 1g.10gb / 2g.20gb. ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/altas/?utm_source=openai))\n\n6) Yuegroup: A100: 4 nodes \u00d7 4 A100/node = 16 A100; inferred A100 80GB from MIG example 3g.20gb. A6000: node c0005 has A6000 GPUs but GPU count not stated; estimated as 4\u00d7 A6000 on that node (typical 4-GPU workstation/server layout). ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/yuegroup/))\n\n7) CAPECRYSTAL: 5 nodes \u00d7 4 V100/node = 20 V100. ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/capecrystal/?utm_source=openai))\n\n8) POOL: node c0105 \u00d7 8 RTX A6000 Ada/node = 8 (counted into a6000_count, also listed explicitly under other_high_vram_gpus). ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/clusters/pool-hardware/))\n\nExcluded from totals: Red Cloud GPU instances list supported GPU models but does not publish total physical GPU inventory, so no nodes\u00d7GPUs calculation possible from public docs. ([portal.cac.cornell.edu](https://portal.cac.cornell.edu/techdocs/redcloud/gpu_instances/?utm_source=openai)) [WARNING: Original source was inaccessible, using fallback.]"
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched in this query."
  },
  "analysis_notes": "Data collected via multi-query approach: separate student and GPU searches."
}