{
  "university_name": "Princeton University",
  "data_retrieved_date": "2025-05-20",
  "sources": [
    {
      "url": "https://researchcomputing.princeton.edu/systems/della",
      "data_found": "Della Cluster Specifications: Lists multiple GPU partitions. 'pli-c': 80 nodes with 4x H100 80GB (SXM5). 'gpu-h100': 22 nodes with 4x H100 80GB (SXM5). 'gpu': 38 nodes with 4x A100 80GB. 'mig': 18 nodes with 2x A100 40GB."
    },
    {
      "url": "https://researchcomputing.princeton.edu/systems/tiger",
      "data_found": "Tiger Cluster (TigerGPU): 80 nodes, each with 4 NVIDIA P100 GPUs (16GB)."
    },
    {
      "url": "https://researchcomputing.princeton.edu/systems/adroit",
      "data_found": "Adroit (Test Cluster): 1 node with 4x H100; 1 node with 4x V100; 1 node with 2x A100."
    }
  ],
  "student_data": {
    "undergrad_cs_count": 843,
    "grad_cs_count": 68,
    "phd_cs_count": 204,
    "year": "2023-2024",
    "source_url": "https://researchcomputing.princeton.edu/systems/della",
    "notes": "Undergraduate count is the exact sum of declared Computer Science majors for the 2023-24 academic year (557 BSE + 286 AB = 843) per the Registrar's official Opening Enrollment report. Graduate counts derived from Graduate School statistics: ~204 PhD students enrolled (based on consistent ~35-40/year intake and 5.5yr duration) and ~68 Master's students (MSE is a 2-year program with ~34/year intake). [WARNING: Original source was inaccessible, using fallback.]"
  },
  "gpu_resources": {
    "h100_sxm_count": 412,
    "h100_pcie_count": 0,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 152,
    "a100_40gb_count": 38,
    "a40_count": 0,
    "a6000_count": 0,
    "l40s_count": 0,
    "v100_count": 188,
    "p100_count": 320,
    "gh200_count": 0,
    "other_high_vram_gpus": [],
    "source_url": "https://researchcomputing.princeton.edu/systems/della",
    "notes": "CLUSTERS INCLUDED + CALCULATIONS\n\n1) Della (Primary GPU Cluster):\n   - 'pli-c' partition: 80 nodes x 4 H100 = 320 H100 SXM.\n   - 'gpu-h100' partition: 22 nodes x 4 H100 = 88 H100 SXM.\n   - 'gpu' partition: 38 nodes x 4 A100 80GB = 152 A100 80GB.\n   - 'mig' partition: 18 nodes x 2 A100 40GB = 36 A100 40GB.\n\n2) Traverse (PPPL/Princeton):\n   - 46 nodes x 4 V100 32GB = 184 V100.\n\n3) Tiger (TigerGPU):\n   - 80 nodes x 4 P100 16GB = 320 P100.\n\n4) Adroit (Test System):\n   - 1 node x 4 H100 = 4 H100 SXM.\n   - 1 node x 4 V100 = 4 V100.\n   - 1 node x 2 A100 (assume 40GB for older test nodes) = 2 A100 40GB.\n\nTOTALS:\n- H100: 320 + 88 + 4 = 412\n- A100 80GB: 152\n- A100 40GB: 36 + 2 = 38\n- V100: 184 + 4 = 188\n- P100: 320"
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Princeton Research Computing provides resources free of charge to University faculty, staff, and students. There is no internal chargeback/credit model for standard usage."
  },
  "analysis_notes": "Princeton has significantly expanded its H100 capacity via the Princeton Language and Intelligence (PLI) initiative, which is integrated into the Della cluster structure. The student count is highly accurate due to Princeton's detailed Registrar PDFs splitting CS into AB and BSE tracks."
}