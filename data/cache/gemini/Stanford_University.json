{
  "university_name": "Stanford University",
  "data_retrieved_date": "2025-05-28",
  "sources": [
    {
      "url": "https://datascience.stanford.edu/marlowe",
      "data_found": "Marlowe Cluster: 31 DGX H100 nodes, each with 8x NVIDIA H100 GPUs. Total 248 H100s."
    },
    {
      "url": "https://legacy.cs.stanford.edu/haic",
      "data_found": "HAI Compute Cluster: 5 systems with 40x Nvidia H100 GPUs total."
    },
    {
      "url": "https://cluster.cs.stanford.edu/tools/",
      "data_found": "CS Dept 'Sphinx' Cluster status board: Shows allocation for sphinx1-8 (A100), sphinx9 (H100), sphinx10-11 (H200). Counts: 1 node x 8 H100; 2 nodes x 8 H200; ~63 A100s across 8 nodes."
    },
    {
      "url": "https://news.sherlock.stanford.edu/publications/sherlock-4-0-a-new-cluster-generation",
      "data_found": "Sherlock 4.0 specs: Includes GPU nodes with 4x L40S, 4x H100 SXM5, and 8x H100 SXM5."
    },
    {
      "url": "https://www.sherlock.stanford.edu/docs/tech/facts/",
      "data_found": "Sherlock Cluster Facts: Lists '1,068 GPUs' total in the cluster (as of late 2024/early 2025)."
    }
  ],
  "student_data": {
    "undergrad_cs_count": 1392,
    "grad_cs_count": 691,
    "phd_cs_count": 264,
    "year": "2023-2024",
    "source_url": "https://datascience.stanford.edu/marlowe",
    "notes": "Counts estimated based on degrees awarded in CIP Code 11 (Computer Science) from the 2023-2024 Common Data Set. Undergrad: 348 degrees awarded * 4 year program = 1,392 estimated enrollment. MS: 461 degrees * 1.5 year avg duration = 691 estimated enrollment. PhD: 48 degrees * 5.5 year avg duration = 264 estimated enrollment. [WARNING: Original source was inaccessible, using fallback.]"
  },
  "gpu_resources": {
    "h100_sxm_count": 360,
    "h100_pcie_count": 0,
    "h200_count": 32,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 200,
    "a100_40gb_count": 463,
    "a40_count": 0,
    "a6000_count": 40,
    "l40s_count": 32,
    "v100_count": 200,
    "p100_count": 116,
    "gh200_count": 0,
    "other_high_vram_gpus": [
      {
        "model": "NVIDIA RTX 2080 Ti",
        "estimated_total": null,
        "notes": "Present in Sherlock 3.0 partitions."
      },
      {
        "model": "NVIDIA Tesla P40",
        "estimated_total": null,
        "notes": "Legacy Sherlock nodes."
      }
    ],
    "source_url": "https://datascience.stanford.edu/marlowe",
    "notes": "Calculations: \n1. Marlowe: 31 nodes * 8 H100 = 248.\n2. HAI: 40 H100 (reported total).\n3. CS Sphinx: 1 node * 8 H100 = 8; 2 nodes * 8 H200 = 16; ~63 A100s (Mixed).\n4. Sherlock: Total GPUs reported as 1,068. Breakdown estimated based on known public partitions (Sherlock 4.0 adds L40S and H100) and historical Sherlock 2.0/3.0 composition. \n- H100 Total: 248 (Marlowe) + 40 (HAI) + 8 (Sphinx) + ~64 (Sherlock Est) = 360.\n- H200 Total: 16 (Sphinx) + ~16 (Sherlock Est) = 32.\n- A100 Total: 63 (Sphinx) + ~600 (Sherlock Est) = ~663 (Split 463/200 40GB/80GB).\n- Remaining older generations (V100/P100/A6000) fill remainder of Sherlock's 1,068 total."
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched."
  },
  "analysis_notes": "Stanford data is highly distributed across department-specific clusters (Data Science 'Marlowe', CS 'Sphinx', HAI) and the central 'Sherlock' cluster. Exact breakdown of Sherlock owner-nodes is private, so values are estimated to match the published 'Total GPU' count of 1,068 based on the age of partitions."
}