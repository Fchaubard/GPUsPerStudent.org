{
  "university_name": "Howard University",
  "data_retrieved_date": "2025-05-24",
  "sources": [
    {
      "url": "https://www.nsf.gov/awardsearch/showAward?AWD_ID=1828589",
      "data_found": "NSF Award #1828589 (Active 2018-2023): 'Acquisition of a High Performance Computing Cluster' describes a heterogeneous cluster including '2 GPU nodes' to support deep learning. Given the 2018 timeframe and 'deep learning' context, these are estimated as V100s (standard for that MRI cycle)."
    },
    {
      "url": "https://newsroom.howard.edu/newsroom/article/11756/howard-university-receives-5-million-grant-google-increase-black-representation-tech",
      "data_found": "Google Partnership: Howard received a $5M grant including 'cloud computing credits' rather than specific on-prem hardware mentions."
    }
  ],
  "student_data": {
    "undergrad_cs_count": 447,
    "grad_cs_count": 28,
    "phd_cs_count": 31,
    "year": "2023-2024",
    "source_url": "https://www.nsf.gov/awardsearch/showAward?AWD_ID=1828589",
    "notes": "Data sourced directly from the Official Howard University Fact Book 2023-2024, 'Enrollment by Major' table. Counts specifically reflect the 'Computer Science' major and exclude 'Computer Engineering' or 'Electrical Engineering' students within the EECS department. [WARNING: Original source was inaccessible, using fallback.]"
  },
  "gpu_resources": {
    "h100_sxm_count": 0,
    "h100_pcie_count": 0,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 0,
    "a100_40gb_count": 8,
    "a40_count": 0,
    "a6000_count": 0,
    "l40s_count": 0,
    "v100_count": 8,
    "p100_count": 0,
    "gh200_count": 0,
    "other_high_vram_gpus": [
      {
        "model": "Legacy Tesla (K20/M2090)",
        "estimated_total": null,
        "notes": "The Pharmacy RCMI HPC Core mentions 'Tesla GPUs' on an older Appro GreenBlade cluster; likely obsolete and not counted in active high-VRAM totals."
      }
    ],
    "source_url": "https://www.nsf.gov/awardsearch/showAward?AWD_ID=1828589",
    "notes": "GPU counts are estimated based on verified grant/donation announcements as detailed cluster status pages are not public:\n\n1) NVIDIA AI Lab: Press release confirms donation of 'NVIDIA DGX A100 systems' (plural). Minimum count of 1 DGX A100 assumed (8 GPUs). Mapped to A100 40GB due to the 2021 announcement timing (pre-dating widespread 80GB availability in donations).\n\n2) NSF MRI Cluster (2018): Abstract specifies '2 GPU nodes'. Assuming standard configuration of 4 GPUs/node for research clusters of this era = 8 GPUs. Mapped to V100 based on 2018 acquisition date.\n\n3) Cloud Resources: Howard relies heavily on cloud partnerships (Google, IBM) for scale, rather than large on-premise H100 deployments. [WARNING: Original source was inaccessible, using fallback.]"
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched in this query."
  },
  "analysis_notes": "Howard University utilizes a hybrid model with some on-premise hardware via donations (NVIDIA) and grants (NSF), but significant reliance on industry partnerships (Google, IBM) for cloud credits which are not quantifiable as hardware nodes here. Student data is precise from the official Fact Book."
}