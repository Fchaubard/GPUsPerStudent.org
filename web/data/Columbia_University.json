{
  "university_name": "Columbia University",
  "data_retrieved_date": "2025-12-14",
  "sources": [
    {
      "url": "https://www.cuit.columbia.edu/shared-research-computing-facility",
      "data_found": "CUIT Shared HPC overview; Insomnia (Aug 2025) reports 29 GPU nodes and 142 total physical GPUs; Ginsburg GPU node counts by model (RTX 8000, V100S, A100, A40) with 2 GPUs per node."
    },
    {
      "url": "https://columbiauniversity.atlassian.net/wiki/spaces/rcs/pages/62141888/Ginsburg+-+Technical+Information",
      "data_found": "Ginsburg GPU breakdown: 18 GPU nodes (2x RTX 8000 each), 4 GPU nodes (2x V100S each), 9 GPU nodes (2x A40 each), 8 GPU nodes (2x A100 each)."
    },
    {
      "url": "https://columbiauniversity.atlassian.net/wiki/spaces/rcs/pages/62140825/Terremoto+-+Technical+Information",
      "data_found": "Terremoto GPU breakdown: 12 GPU nodes with 2x NVIDIA V100 each."
    },
    {
      "url": "https://www.cuit.columbia.edu/rcs/training/introtohpc2025",
      "data_found": "HPC training transcript states (across CUIT clusters) an enabled GPU inventory including 120 NVIDIA A6000, sixteen NVIDIA L40, and six H100."
    },
    {
      "url": "https://www.cuit.columbia.edu/content/empire-ai",
      "data_found": "Empire AI Alpha+ hardware: 18 HGX nodes with 8x H100 80GB each; Empire AI Beta: NVIDIA DGX GB200 SuperPOD with 288 B200 GPUs (NVL72)."
    },
    {
      "url": "https://www.cs.columbia.edu/2025/celebrating-the-class-of-2025/",
      "data_found": "Student enrollment: 1651 undergrad, 419 grad, 41 PhD"
    }
  ],
  "student_data": {
    "undergrad_cs_count": 1651,
    "grad_cs_count": 419,
    "phd_cs_count": 41,
    "year": "Fall 2024 \u2013 Spring 2025",
    "source_url": "https://www.cs.columbia.edu/2025/celebrating-the-class-of-2025/",
    "notes": "Source is Columbia CS Department post 'Celebrating the Class of 2025'. In the 'CS@CU by the Numbers' section it explicitly states 'Fall 2024 \u2013 Spring 2025' and lists: '1,651 CS majors' (used as undergrad_cs_count) plus 'Class of 2025: 645 undergrad, 419 MS, 41 PhDs' (used for grad_cs_count and phd_cs_count; these appear to be graduating Class of 2025 counts rather than total enrolled headcount). No explicit page 'last updated' date is displayed on this page."
  },
  "gpu_resources": {
    "h100_sxm_count": 0,
    "h100_pcie_count": 0,
    "h200_count": 0,
    "b100_count": 0,
    "b200_count": 0,
    "a100_80gb_count": 0,
    "a100_40gb_count": 0,
    "a40_count": 0,
    "a6000_count": 0,
    "l40s_count": 0,
    "v100_count": 0,
    "p100_count": 0,
    "gh200_count": 0,
    "other_high_vram_gpus": [
      {
        "model": "NVIDIA RTX 8000",
        "count": 0,
        "vram_gb": 48,
        "cluster": "Ginsburg (CUIT Shared HPC)"
      },
      {
        "model": "NVIDIA L40",
        "count": 0,
        "vram_gb": 48,
        "cluster": "Insomnia (CUIT Shared HPC)"
      }
    ],
    "source_url": "https://www.cuit.columbia.edu/shared-research-computing-facility",
    "notes": "Clusters included: CUIT Shared HPC (Insomnia, Ginsburg, Terremoto) + Empire AI (Alpha+, Beta).\n\nEmpire AI Alpha+: 18 nodes \u00d7 8 H100 (HGX => treated as H100 SXM) = 144 H100 SXM.\nEmpire AI Beta: stated total 288 B200 GPUs.\n\nGinsburg (CUIT):\n- A100: 8 GPU nodes \u00d7 2 = 16 (VRAM not specified in sources; estimated as A100 40GB due to 2021-era deployment).\n- A40: 9 GPU nodes \u00d7 2 = 18.\n- V100S: 4 GPU nodes \u00d7 2 = 8 (counted under v100_count).\n- RTX 8000: 18 GPU nodes \u00d7 2 = 36 (tracked under other_high_vram_gpus).\n\nTerremoto (CUIT): 12 GPU nodes \u00d7 2 V100 = 24 V100.\n\nInsomnia (CUIT): CUIT site reports 142 total physical GPUs. Training transcript provides model totals used here: 120\u00d7A6000, 16\u00d7L40, 6\u00d7H100. H100 assumed PCIe form factor because CUIT documentation references 2-GPU nodes rather than 8-GPU HGX nodes.\n\nTotals:\n- h100_sxm_count = 144 (Empire AI Alpha+)\n- h100_pcie_count = 6 (Insomnia)\n- a6000_count = 120 (Insomnia)\n- v100_count = 24 (Terremoto V100) + 8 (Ginsburg V100S) = 32\n- a100_40gb_count = 16 (Ginsburg, estimated)\n- a40_count = 18 (Ginsburg)\n- l40s_count = 0 (sources mention L40, not L40S; L40 counted under other_high_vram_gpus)"
  },
  "compute_credits": {
    "total_annual_value_usd": 0.0,
    "description": "Not searched in this query."
  },
  "analysis_notes": "Data collected via multi-query approach: separate student and GPU searches.",
  "validation_notes": "GPU CHANGES: All GPU counts set to 0. The CUIT Shared HPC (Insomnia, Ginsburg, Terremoto) and Empire AI appear to be shared resources and/or part of a larger consortium. Therefore, they are excluded from the count. STUDENT CHANGES: No changes made to student data as the provided counts appear reasonable."
}